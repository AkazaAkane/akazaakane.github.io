[{"title":"Minimax Speech 2.0","url":"/2025/06/04/Minimax Speech 2.0/","content":"\n原文链接 [https://arxiv.org/pdf/2505.07916](https://arxiv.org/pdf/2505.07916)\n\n## 导言\n我个人对Minimax这个公司还是比较友好感的：之前听过几次他们ceo和cto的podcast，能感受到他们不仅有商业上的布局，在技术上也有坚定的追求（linear attention）。所以，我对他们的新模型还是蛮期待的。事实证明，这一次新的tts模型用起来确实很优秀，尤其是在中文语音中。不过这篇技术报告内容一般，一半以上的篇幅都在讲自己效果怎么怎么好，感觉目的可能是秀肌肉居多而不是分享，猜测可能公司有融资方面的压力。\n\nMinimax Speech 2.0是一个自回归的transformer架构tts（文生语音）模型，并且达到了sota的结果。这个模型的创新点在于，运用了一个科学系的speaker encoder使得0-shot learning成为可能，并且有也支持one shot。不仅如此，模型还运用了flow matching和flow vae decoder使得生成的效果更好。\n\n## 数据\n很可惜，这篇技术报告并没有提到训练具体的数据细节，只是含糊的讲了大家都知道的东西：文中提到，训练用了32种语言的数据目前我印象里比较全的tts模型数据的描述还是来自几年前的open-ai whisper，感觉国内厂商在这一方面还是比较保守。\n\n## 模型结构\n模型的架构是经典的多模态架构：分别将不同模态压缩到一个unified space，然后decode出output。具体来讲，文字是用了经典的bpe作为encoder，语音则是用了Speaker Encoder + Audio Tokenizer，一个用来提取声音特征一个用来提取内容。与其他tts模型不同的是，minimax没有用一个pre-trained的audio encoder，而是把这个encoder和ar transformer用来一起训练。这么做的优点在于，pre-trained encoder的语料数据不够丰富，个人猜测可能对于中文的效果不好，minimax这一次应该是在数据方面加强了中文语料。\n\n架构上的创新使得minimax可以实现高质量的0-shot learning，也就是用户只需要上传一段reference的语音就可以直接通过文字输出想要的声音克隆片段。相比之下，传统的语音模型需要 语音-文本 对进行 1-shot或者fine-tuning 才能达到不错的效果。\n\n## flow matching\n\n\n根据文档内容，MiniMax-Speech的模型结构在分别对文本和音频进行编码后，主要通过**自回归Transformer**和** latent flow matching模块（含Flow-VAE）**实现语音合成。以下是具体流程和关键组件的详细描述：\n\n\n\n### **1. 自回归Transformer：生成离散音频 tokens**  \n- **输入条件**：  \n  - 文本编码后的 tokens（记为 \\( c \\)）。  \n  - 说话人编码器输出的条件向量（记为 \\( v \\)），用于指定目标说话人的音色和风格。  \n- **处理逻辑**：  \n  自回归Transformer以文本 tokens 为输入，结合说话人条件向量 \\( v \\)，通过注意力机制逐步生成离散音频 tokens（记为 \\( z \\)）。这一过程模仿人类语音生成的时序特性，擅长捕捉韵律和语调的自然变化（文档段落、）。  \n- **优势**：  \n  相比非自回归模型，自回归架构无需显式建模音素持续时间对齐，通过隐式学习生成更自然的语音节奏。\n\n\n### **2. Latent Flow Matching模块：从离散 tokens 到连续语音特征**  \n自回归Transformer输出的离散音频 tokens \\( z \\) 随后进入Latent Flow Matching模块，该模块包含两个关键组件：  \n\n##### **(1) Flow-VAE：优化潜在特征表示**  \n- **结构与功能**：  \n  - **Encoder**：将离散音频 tokens \\( z \\) 转换为连续语音特征（潜在变量 \\( \\tilde{z} \\)），捕捉音频的声学细节（如音高、音色）。  \n  - **Flow Model**：对潜在变量 \\( \\tilde{z} \\) 的分布进行可逆变换，将其映射到标准正态分布，以增强特征的表达能力和分布拟合能力（文档段落、）。  \n  - **Decoder（神经声码器）**：将潜在变量 \\( \\tilde{z} \\) 还原为音频波形 \\( x \\)，通过KL散度约束确保重建精度（文档段落、）。  \n- **创新点**：  \n  传统VAE假设潜在空间为标准正态分布，而Flow-VAE通过流模型的可逆变换（如仿射变换、置换），学习更复杂的后验分布，从而更准确地捕捉语音数据的多模态特征（文档段落）。实验表明，Flow-VAE的波形重建误差低于传统VAE，且生成的语音特征更紧凑、信息更丰富（文档段落、）。\n\n#### **(2) 流匹配模型（Flow Matching Model）**  \n- **输入条件**：  \n  - 自回归Transformer生成的离散音频 tokens \\( z \\)（经Flow-VAE编码为潜在变量 \\( \\tilde{z} \\)）。  \n  - 说话人条件向量 \\( v \\) 和文本编码后的上下文信息 \\( c \\)（用于引导合成语音的风格和内容对齐）。  \n- **处理逻辑**：  \n  流匹配模型基于Transformer架构，对潜在变量 \\( \\tilde{z} \\) 的分布进行建模，通过匹配数据分布与先验分布（如标准正态分布），生成高质量的连续语音特征。该过程无需显式建模时长，而是通过隐式学习捕捉语音的时序依赖（文档段落、）。  \n- **优势**：  \n  相比直接预测下一个 token（Next Token Prediction），流匹配模型通过连续潜在空间的分布建模，避免了离散空间的量化误差，且能更灵活地处理语音的动态范围和细节变化（文档段落、）。\n\n\n\n\n","tags":["技术","论文","Minimax"]},{"title":"Seedream 3.0 Technical Report","url":"/2025/04/21/Doubao Seedram 3.0/","content":"\n原文链接 [https://arxiv.org/pdf/2504.11346](https://arxiv.org/pdf/2504.11346)\n\n## 导言\nSeedream 2.0 虽然已经很好了，但是还有一些问题：模型在复杂prompt上的对齐有待提高，尤其是在数字精度和多物体空间关系的情况下；2.0对于图片内文字的生成能力有待提升；图片美学上的问题；以及生成图片的清晰度问题。对于以上问题，豆包做了一下提升：在数据层面，引入了双倍的高质量数据；增加了训练步骤和技巧，比如混合resolution training，多模态rope，新的representation alignment loss，以及resolution aware sampling。最后，也对后训练和生成加速做了提升。总而言之，3.0是一次对于2.0的incremental change，但是仅仅才过了一个月。从这能看出来字节豆包组的含金量，以及好的ai infra对于持续research和产品迭代的重要性。\n\n## 数据\n文章提到，2.0阶段运用了严格的数据筛选机制，所以这限制了训练数据的数量。在3.0中，豆包运用了新的筛选机制，把defect小于20%的数据保留下来，并且在训练的时候运用了spatial attention mask使得这些区域会被排除出训练，在保证模型稳定性的情况下成功扩展了差不多20%的训练数据。\n\n## 预训练\n模型结构沿用了2.0，只是增加了训练参数和以下的技巧：\n1.混合清晰度（resolution）训练。具体的讲，因为transformer天然支持不同长度的sequence，豆包组先用 256^2 的数据做pre-train，然后再更高清晰度（512^82 to 2048^2）的数据上做微调。并且，额外添加了size embedding作为额外的condition（应该是做了crocs attention？），使得模型能在没见过的清晰度情况下依然表现出色。\n2.Cross-modality Rope。在2.0中，运用的是scaling rope。在3.0中，对于这个技巧做了提升。以往我们会对text做1d rope，对图片做2d。但是在cm rope里，会把text也当作一维的2d，做2d rope并投射到2d空间和图片关联起来。\n3.运用了flow matching的损失函数，并且增加了alignment loss （用来对齐自己的mmdit和dinov2）可以让加速模型收敛。\n4.Resolution-aware Timestep Sampling是一项diffusion模型训练的技巧，原理是在不同的resolution下对于我们sample的distribution做改变：high resolution图片会让sampling dist更偏向于lower snrs/higher noise levels。在训练阶段是用数据集的平均的resolution，inference的时候用期望的resolution来决定shift factor。具体做法是先从log-normal sample，然后根据我们算出来的shift factor做shifting。\n\n## 后训练\n相比于2.0，3.0取消的refiner阶段因为模型本身已经能够生成不同resolution的图片。除此之外，还做了以下提升：为了ct和sft的阶段训练了更多的captioning model，能更好的让模型理解prompt中的美学，style和layout；平衡了数据里不同resolution数据的数量。\n\n还有一点是用了vlm而不是clip作为奖励函数，具体做法如下：\n1.Instruction as Query: The model receives a prompt, such as \"A cat sitting on a couch.\"​\n2.Formulating the Question: This prompt is transformed into a question like, \"Does this image depict a cat sitting on a couch? Please answer Yes or No.“ \n3.Evaluating with VLM: The VLM processes the generated image and the question, outputting probabilities for \"Yes\" and \"No.\"​\n4.Deriving the Reward: The probability assigned to \"Yes\" is normalized and used as the reward signal. A higher probability indicates better alignment between the image and the prompt.\n\n### 模型加速\n\nseedream3.0的模型加速基于Hyper-SD和RayFlow，相比于传统的扩散模型在降噪过程中所有的样本都是通过一样的高斯分布路径，seedream对不同样本实现了个性化的单一通路，提升了模型的稳定性和生成的多元化。并且使用了一个预训练的模型来对噪声进行预估，这个方法使得模型在加噪和去噪的过程中能以最大可能性进行收敛，使得模型现在可以用较少的步数得到非常好的结果。在训练加速上，训练了一个结合Stochastic Stein Discrepancy (SSD)的neural net来预测哪个timestamp会产生最大的training loss，所以在训练采样的时候区别于传统的uniform sampling可以更高效的采样most important timesteamps。结合以上的工作，豆包的模型得以更高的效率达到普通扩散模型采样50步才能到达的效果。\n\n\n","tags":["技术","豆包","论文"]},{"title":"2025-03-23 本周播客记录","url":"/2025/03/23/2025-03-23 本周播客记录/","content":"\n### 起朱楼宴宾客 vol:120 日本医疗体系\n\n本集博客讲述日本怎么样走出医保崩溃，对于中国的现状和未来起到了一定的启示作用。日本的医保可以分为90-05年的崩溃期，以及05到如今的重生期。从需求端 - 人来讲，日本政府其实很早就预料到了老龄化会加重，但是由于低估了老龄化的速度和老龄人慢性病对医疗资源的占用，医保政策几近崩溃。而现在，虽然老龄化更严重了，但是日本医生采用免费健诊和提前防控，大大降低了慢性病的出现速度和概率。需求端 - 资金来讲，日本现在医保是全覆盖，有上限，独立的老年人保险制度。供给端分为三个部分，医疗服务，资金注入和药品。在崩溃时期，日本有着巨大的医生缺口和剧烈的医患矛盾。在重生时期，日本实行了分诊制，社区化，提升医疗了效率。在资金供给方面，日本在崩溃时期像现在的中国一样，有着医疗费亡国危机。因此，政府实行了医疗削减法案和廉价医疗，但是效果十分糟糕。在经历改革之后，实行了dpc和康复理疗的发展。药品的政策是中国最能借鉴的，在崩溃时期，集采的低价招标策略带来了药品质量危机和创新药危机，日本制药行业大萧条。于是，政府实行了定价改革（政府给定价格，在同价格选择质量最好的），中小企业兼并重组（有创新能力的企业收购仿制药），和药剂师改革。结论是，不可能三角：质量，价格，规模 可能被平衡。\n\n### 声东击西 #339 中国短剧登录好莱坞\n\n短剧现在大批量进入美国市场，一般是中国国内火的剧本直接拿到LA找当地演员拍摄。相比于传统电视剧，短剧成本低，时间短，剧情没什么深度。并且，资方权限大，导演只是负责剧本：资方会根据大数据选择演员，按照特征（发色/瞳色）来挑选演员。好莱坞工会的罢工使得岗位减少，最好的人只能去争取次一级的剧，导致很多导演，工作人员，演员流动到短剧。\n\n### 科技早知道 S9E07 特斯拉暴跌，美股回调\n\n特斯拉暴跌，跟很多🐎粉声称索罗斯等人的恶意做空没什么关系。主要原因是，川普上任后表现不及预期，导致川普溢价 - 特斯拉，数字货币和川普公司等都跌回选前水平。英伟达需要新的叙事，虽然deepseek出来以后正反观点依然在博弈，但是已经不像以前那样无人质疑。只要有人开始质疑，那需要新的所有人都认同的叙事才能支持这种高估值。\n\n### 科技早知道S8E32 谷歌量子计算芯片willow\n\n谷歌的新芯片有100个量子比特，并且能支持纠错，但是大规模商用的芯片需要100万个，任重道远。长期来讲，区块链和现在的加密方式有被破译的可能。\n\n### 晚点聊107 Haivivi月入千万的ai jellycat\n\n嘉宾以前是天猫精灵的团队领导，他们发现跟天猫精灵互动最多的是孩子，所以出来创业做ai毛绒玩具。主打的是陪伴市场，因为不想跟大公司竞争教育，并且大模型的能力更适合作为毛绒玩具陪伴。在孩子眼里，毛绒玩具说话很正常，所以不需要教育市场。对于成年来说也是，因为现在毛绒玩具其实最大的买家是年轻人，因为能提供情绪价值。\n\n\n\n\n\n","tags":["podcast","技术"]},{"title":"设定系推理的减法艺术：为何我不喜欢《献给名侦探的甜美死亡》","url":"/2025/03/20/设定系推理的减法艺术/","content":"\n最近读完了方丈贵惠的《献给名侦探的甜美死亡》，正好借此聊一聊设定系推理小说。近年来，日本设定系推理小说以“规则创新”为旗号，掀起了一股“万物皆可设定”的狂潮。从时间循环到超能力预言，从丧尸围城到AI破案，作家们不断用天马行空的框架重构本格推理的边界。然而，当我在阅读方丈贵惠的《献给名侦探的甜美死亡》时，却感受到一种被“过度设定”反噬的疲惫——这部作品将VR游戏、双重暴风雪山庄、狼人杀机制、现实与虚拟空间交互等元素堆砌成一座繁复的迷宫，最终让我迷失在规则的泥潭中。相比之下，白井智之的和今村昌弘的却以“极简规则”创造出令人拍案叫绝的诡计。这种反差促使我反思：设定系推理的魅力，或许不在于规则的复杂程度，而在于如何用最少的“砖石”搭建出最精妙的“逻辑之塔”。\n\n### 正文（不涉及剧透部分）\n\n《献给名侦探的甜美死亡》讲述的故事是，加茂冬马 & 龙泉佑树（作者同系列作品的两个主角），接受了VR游戏《谜案创造者》开发商巨齿鲨游戏游戏试玩会的邀请会，来到孤岛上的巨齿鲨山庄。但是游戏还没开始，每个人被告知自己最重要的人都被当作人质，要想解救家人、平安回去，就必须同时解开发生在现实世界及VR世界里的命案。\n\n在还没开始看之前，我一下就想到了山口雅也1989年的《克莱因壶》，以及我心目中的二次元最经典作品《刀剑神域》和，之前火爆的电影《头号玩家》。1935年，美国科幻小说家斯坦利·威因鲍姆（Stanley Weinbaum）就发表了《皮格马利翁的眼镜》（Pygmalion's Spectacles）。这部小说被认为是第一个探讨虚拟现实系统的科幻作品，描述了一种包括嗅觉、触觉和全息护目镜的虚拟现实系统。到此为止，好像我们只是单纯的谈论了VR这个科幻元素，还没有谈及设定系这一说法。事实上，科幻元素可以算是设定系中的一种非常常见的流派。\n\n那么什么是设定系推理呢？设定系推理指通过引入科幻、奇幻或恐怖等非现实元素，在特殊世界观规则下展开的推理作品。它源自于英国\"诺克斯十诫\"对超自然元素的排斥：\n\n- 故事中不可存有超自然力量。\n- 故事中不应出现不存在的毒药、以及太复杂需要长篇解说的犯案工具。\n- 故事中不可有中国人角色。（实际上是说静止角色拥有超能力）\n\n虽然这些信条不乏有些错误的认知，但在古典推理小说的黄金期时曾被奉为圭臬。逻辑也很简单，因为引入这些元素无法让读者信服。比如说，在解答受害人怎么死的时候，假如作者说“犯人有超能力，直接远程杀死受害人不留下痕迹”，那正常的读者都很难满意。因为一般来讲，推理小说默认了现实世界中的物理定律，所以如果谜底是之前从未提及的超能力的话，那答案其实有无数种，推理这个过程其实可有可无（外星人杀的人，受害者是活死人本来就死了...）。当然，如果事先告诉读者犯人有超能力，且只有一个犯人这种定律，那通过引入这种悬疑的设定反而会让小说变得更有意思。这些元素还不够达成一个好的设定系推理作品。对于推理小说而言，作者会制造一个谜题（比如说杀人案），然后提供一个合乎逻辑的谜底（解答/推理）。假设我们以上讨论的超自然元素和谜面谜底没关系的话，那其实也不能算是设定系小说。比如柯南里有变小药，阿笠博士的地精科技系列：滑板，足力健，ikun背带裤，但这些要素与解开谜团无直接关系，在揭露诡计或找出真凶时基本不会考虑它们的存在，因此通常不被视为特殊设定谜团。假如柯南运用了高科技或者变小药去犯案，那柯南就可以是设定系推理作品。\n\n至此，我们就引入了设定系推理的完整定义：\n\n1. 包含现实相异的物理法则、现象、超能力、高科技等设定，但是需预先建立清晰世界观规则并遵循由此产生的规则（如《死亡笔记》使用手册，或者若存在超能力者，需限定\"每区域仅1人\"等约束条件\n2. 谜题必须基于设定规则展开，也是说之前提到的超自然规则不能和谜题无关\n\n另外，即使没有任何科幻或奇幻元素，以孤岛、外国或过去为背景，讲述只有在该背景中才能解决的谜团和解决办法的推理小说，也可以广义上称为设定系推理小说。 实际上，从2010年代后半期开始，与特殊设定推理小说的繁荣相伴，也出现了以过去时代为背景，以那个时代才有的谜题为主题的严肃推理小说受到高度评价的趋势，比如古城诚二的《战争的底层》、亚门伊吹的《剑与伞》、辻正树的《只是谋杀而已》、米泽帆信的《黑牢城》。\n\n日本的设定系推理发源自1987年绫辻行人出道后开始的新本格运动，在旨在复兴古典侦探乐趣的新侦探类型中，出现了一部里程碑式的作品：山口雅也的《活死人之死》（1989年） ，该作品讲述“发生在死者复活的世界里的谋杀案件”。 《活死人之死》的开创性之处在于它“为了解开谜团而创造了一个完全特殊的世界”。 接下来，1995年出道的西泽康彦推出了一系列科幻悬疑小说，包括具有里程碑意义的时间循环推理小说《死去七次的男人》、描述人物性格相继互换的杀人案的《人格转移杀人案》、以及揭露心灵感应者犯罪的《上雅嗣子的心灵感应事件簿》系列。他宣扬“即使你引入科幻背景，只要你明确规定规则，你也可以写出悬疑小说”的想法。\n\n漫画中，智力战、死亡游戏、基于特殊规则的生存故事，例如前面提到的《死亡笔记》和《未来日记》等，都颇为流行，“基于特殊规则的智力战”的形式也逐渐普及。回顾这段历史，可以说对 现代奇幻推理小说影响最强的，就是《JoJo的奇妙冒险》和福本伸行的作品。 《JoJo》中的替身战斗，以及《赌博》等福本作品中出现的众多特殊游戏，构成了奇幻推理小说的思维方式的基础。 另外，说到特殊设定的推理小说的历史，不能不提的就是2001年开始的热播游戏《逆转裁判》。绫里真宵运用超能力解决谜题的方式，以及因超能力而发生的意想不到的事件，对后来出道的年轻作家产生了巨大的影响。\n\n随后在2009年，绫辻行人创作的《Another》问世，将十足的悬疑、寻找真凶以及基于恐怖般的规则的剧情转折结合在一起。随后， 2010年，米泽穂信的《折断的龙骨》问世，这是一部以剑与魔法的奇幻世界为背景的全方位悬疑小说，其中需要猜测罪犯。“科幻悬疑”一词已不再能够涵盖这些作品。 米泽在《破碎的龙骨》后记中所使用的“特殊设定推理小说”这一术语，后来作为融合了科幻、奇幻、恐怖等元素的推理小说的统称而广为流传。\n\n与此同时，严肃推理小说界也兴起了多重解决方式的风潮 ，追求“出乎意料的逻辑”逐渐成为严肃推理小说的主流。在严肃侦探小说的世界里，一切出乎意料的凶手和诡计早已穷尽，使用叙事技巧的出人意料的叙述和情节也已进入了瓶颈，用读者绝对想不到的逻辑来呈现让他们吃惊的“出乎意料的逻辑”是严肃侦探小说仅存的最后边疆。 而为了呈现这种“意想不到的逻辑”，作品中有意无意引入非现实的设定也变得越来越普遍，比如《煽动磨坊》和《丸太町卢浮宫》等为逻辑战斗而特设的场景，以及森川友树的《白雪公主》中引入“揭示真相的镜子”等。\n\n此次多解热潮由于涉及“多种”解决方案，不可避免地朝着“以逻辑步骤数取胜”的方向发展，并在2010年代中期以深见怜一郎的《不可思议的竞技场》和井上正树的《我已经考虑过那种可能性》达到高潮，之后便陷入停顿。取而代之的是， 白井智之的《晚安人面疮》、 市川忧人的《水母不会结冰》等作品相继出现。这些作品通过引入独特的设定，并根据这些规则展开谜题，不断推出展现“意想不到的逻辑”的作品。近十年来讲，今村昌宏的处女作《尸人庄迷案》和白井智之《象之首》是我个人设定系推理里最喜欢的作品，除此之外方丈贵恵和早坂吝老师也都有不错的作品。\n\n下方内容涉及剧透，请自行选择观看。\n\n### 正文（包含剧透）\n\n回到正题，《献给名侦探的甜美死亡》这部小说以**VR虚拟现实**为核心设定，构建了“现实世界”与“虚拟世界”双重暴风雪山庄，结合狼人杀、剧本杀规则，展开一场名侦探与凶手的智力对决。主角**加茂冬马**因家人被绑架，被迫参与VR游戏《谜案创造者》内测。游戏舞台是现实中的**巨齿鲨山庄**与虚拟的**玩偶屋馆**，玩家需通过VR设备在虚拟空间中破解案件，而现实世界中的玩家生死与游戏结果直接绑定。8名参与者中，1人扮演“凶手”（虚拟世界的凶手），1人是“执行人”（现实世界的真凶），其余为“侦探”。凶手需在虚拟空间作案，侦探需在限定时间内破案，否则现实中对应玩家将被处决。  虚拟空间被杀死，现实世界并不会死亡。虚拟世界的物理规则与现实不同。虚拟案件与现实中连环谋杀同步发生，主角需在破解VR密室的同时，揭露执行人**良田千景姐弟**的复仇计划——他们利用游戏规则制造混乱，试图将龙泉家族的诅咒公之于众。\n\n具体案件和谜题我会放在后面的附录里，感兴趣的可以去观看。我觉得这部分逻辑性和创新性尚可，比上不足（白井和今村）比下有余。然而，这本作品最大的缺陷还是在设定本身上。设定系推理的核心，是通过限定特殊规则，将特殊的规则逻辑压缩到某个极端场景中，从而激发出传统本格难以实现的诡计可能性。今村昌弘的《尸人庄迷案》只运用了“丧尸围城”这个设定，就构建出一场颠覆传统的连环谋杀：丧尸的存在既制造了暴雪山庄模式，又成为“伪造死亡时间”的关键道具（例如凶手利用丧尸咬痕掩盖尸体真实死因）。当读者以为丧尸只是氛围工具时，它们却成了诡计的核心。这种“设定即诡计”的创作思维，让规则不再是装饰，而是推理迷宫中不可或缺的承重墙。\n\n反观《献给名侦探的甜美死亡》，方丈贵惠显然选择了一条截然相反的道路。这部作品试图将VR游戏、现实绑架、狼人杀角色扮演、虚拟与现实空间同步谋杀等元素全部塞进同一容器，结果却让核心诡计被淹没在庞杂的设定中。\n\n小说中，玩家需通过VR设备在“虚拟玩偶屋馆”破解案件，而现实世界的生死与游戏结果绑定。这一设定本身已包含“虚拟空间物理规则”“现实与虚拟时间差”“VR设备机能限制”等多重变量。但作者进一步叠加了“狼人杀式角色分配”（凶手、侦探、执行人）、“管理员权限篡改代码”、“现实绑架者胁迫玩家”等规则，导致读者不得不耗费大量精力厘清“什么能做、什么不能做”。例如“佑树之死”一案中，凶手利用VR镜头焦距切换隐藏尸体转移路径，这一诡计的前提是读者必须完全理解“玩偶屋馆的虚拟空间具有缩放功能”——但这一设定在案件发生前仅被一笔带过，最终解答更像是“作者突然翻开一张隐藏规则卡”。\n\n在优秀设定系作品中，规则与诡计应是“骨肉相连”的整体。然而《献名》的多数案件却呈现出“设定归设定，诡计归诡计”的割裂感。例如“乾山之死”的核心手法是“凶手破坏现实世界的VR设备导致玩家失足坠亡”，这一解答本质上只需“现实与虚拟联动”的基础设定即可成立，但作者偏要引入“虚拟重力模拟系统”“反重力绳索误导”等冗余设定，反而让诡计显得牵强。相比之下，白井智之在《我为妖怪你为怪物》中仅用“妖怪必须遵守承诺”这一条规则，就构建出凶手利用语言陷阱诱骗妖怪自杀的惊天逆转——简单规则的深度挖掘，远胜于复杂设定的浮夸堆砌。\n\n并且当规则过于复杂时，作品往往沦为冰冷的公式说明书，而作品中展现人性的思考的部分很容易被忽略。今村昌弘的《屍人荘》之所以动人，正是因为丧尸危机放大了人性的挣扎（如角色为保护他人主动被咬）。而《献名》中幕后黑手良田姐弟的复仇动机，却因VR规则、家族诅咒、前作关联等多重信息干扰，显得苍白无力。当读者还在纠结“虚拟空间如何同步现实谋杀”时，早已无暇感受角色的绝望与救赎。\n\n设定系推理的初衷，本是为了挣脱现实逻辑的束缚，开辟新的诡计领域。但近年来部分作品陷入“为设定而设定”的误区，仿佛规则的复杂度与作品的创新性成正比。这种倾向的危险性在于，当作家沉迷于搭建规则迷宫时，可能会忘记迷宫的终点必须有一枚璀璨的宝石——那个让人豁然开朗的逻辑核心。读者期待的是，掀开谜底那一瞬间的豁然开朗：原来是这么简单，但是这么意想不到；而不是当谜题揭晓还在困扰：这条谜题是什么意思，和设定有什么关系。\n\n《献给名侦探的甜美死亡》无疑是一部有意思的作品，但它也暴露出设定系推理的潜在危机：当规则复杂到需要说明书才能理解时，推理小说便从“智力的游戏”异化为“设定的奴隶”。相比之下，我更喜欢白井智之笔下那个无限循环的西斯玛，以及今村昌弘镜头前的电梯和丧尸——它们用最简单的规则，撕开了逻辑最深邃的裂缝。他们的成功，恰恰在于他们手握“奥卡姆剃刀”，果断剃除了一切不必要的规则设定。当设定系推理重新学会做“减法”，或许我们才能迎来下一个黄金时代。\n\n### Appendix 《献给名侦探的甜美死亡》案件与谜题解析**\n\n小说共设计了**五起核心案件**，每案均结合VR设定与物理诡计，呈现“虚拟作案→现实联动→多重反转”的复杂结构。\n\n##### **1. 未知之死（虚拟密室：冰块与风压）**  \n- **手法**：虚拟空间中，玩家“未知”被发现死于封闭房间，门窗从内部反锁。凶手利用冰块堵塞通风口，通过空调制造室内外气压差，使门锁在冰块融化后自动闭合，形成密室假象。  \n- **关键点**：VR环境模拟物理规则，但玩家需意识到“虚拟空间的密室可通过现实物理原理破解”。\n##### **2. 佑树之死（双重空间与玩偶屋馆）**  \n- **手法**：虚拟空间中的“佑树”死于玩偶屋馆的缩小模型房间。凶手利用VR视角切换的盲区，将尸体从正常空间转移到缩小模型内，制造“不可能位移”。  \n- **解答**：玩家发现玩偶屋馆的模型与真实空间比例一致，通过调整VR镜头焦距，可隐藏尸体转移路径。\n##### **3. 乾山之死（绳索与重力误导）**  \n- **手法**：虚拟空间中，玩家“乾山”的尸体悬挂于高塔，现场无攀爬工具。凶手利用VR服的重力模拟功能，在虚拟环境中伪造“反重力绳索”，误导侦探认为凶手具备飞行能力。  \n- **反转**：实际是凶手在现实世界破坏VR设备，导致乾山在虚拟空间中失重坠亡。\n##### **4. 栋方之死（VR服毒杀与时间差）**  \n- **手法**：玩家“栋方”在虚拟空间中中毒身亡，但VR环境无法直接下毒。凶手提前在现实世界对栋方的VR服注射神经毒素，利用游戏时间与现实时间的延迟，制造“虚拟中毒”假象。  \n- **关键线索**：VR服内置的生命监测系统显示栋方在进入游戏前已出现中毒体征。\n##### **5. 不破之死（虚拟场景重构与执行人身份）**  \n- **手法**：执行人“不破”在虚拟空间中被杀，凶手通过篡改游戏代码，在案件发生后重构VR场景，掩盖作案痕迹。最终揭露不破实为良田千景的替身，其死亡是千景为混淆视线设计的“伪解答”。  \n- **核心诡计**：执行人利用管理员权限，在虚拟与现实之间切换身份，制造不在场证明。\n\n### Reference\n[niconico百科](https://dic.nicovideo.jp/t/a/%E7%89%B9%E6%AE%8A%E8%A8%AD%E5%AE%9A%E3%83%9F%E3%82%B9%E3%83%86%E3%83%AA)\n[关于设定系推理的碎碎念](https://www.douban.com/note/843805948/?_i=2430319ZegaBIr)\n[设定之外的世界](https://www.douban.com/note/866785996/?_i=2430323ZegaBIr)\n\n\n\n","tags":["杂谈","推理小说","读书"]},{"title":"Seedream 2.0: A Native Chinese-English Bilingual Image Generation Foundation Model","url":"/2025/03/16/Doubao Seedram 2.0/","content":"\n原文链接 [https://arxiv.org/pdf/2503.07703](https://arxiv.org/pdf/2503.07703)\n\n## 导言\n\n豆包团队针对现有flux、Midjourney、SD3.5等模型对于1.模型长文本和多语言（中文）能力不足；2.不能理解中国文化 的问题，提出了seedream 2.0中英双语大模型。模型的创新性在于数据处理平台，双语言编码器以及后训练。这是一份33页的技术报告，写的非常详细。数据环节的解释非常清晰，编码器的结构和后训练环节的创新也很有亮点。尤其是后训练部分，细节多到令人感动。这篇文章让我感受到字节/豆包的底蕴，不愧是不惜血本挖人的宇宙厂，科研能力和产品能力都没得说。\n\n### 数据\n\n数据的组成包括高质量数据，分布保持数据，知识注入，以及一些针对性补充数据。高质量数据和其他模型的数据集差不多（clarity,aesthetic)，分布保持是做down sampling，在保持原始数据分布情况下减少低质量数据。知识注入包括了很多高质量的中文图文数据，并且其中一部分是只有中国文化有的数据。\n\n数据清理分三步的漏斗系统。第一步，计算quality score, structure score(水印，logo)，然后用ocr去identify text。不符合的数据会被剔除；第二步，分层的进一步筛选。第三步，captioning 和 re-captioning。captioning的部分，豆包会对每一张图做 generic （长句子，短句子） 和 specialized （图片中的文字，美学，想象力）标注。\n\n豆包还设计了一个active learning engine，先标注少量数据训练分类器，再利用分类器从无标注图像中挑选有价值的样本继续标注，形成 “标注 — 训练 — 再筛选” 的循环，逐步完善数据集。\n\n### 双语言编码器\n![](/img/2025/03/5.png) \n\n现有扩散模型一般用clip或者t5当作text encoder，因为他们的embeddings 分布比较符合扩散模型。LLM虽然能力很强，但是它的数据分布不对。为了解决这个情况，豆包收集了高质量中文数据微调了decoder only 大模型，并针对渲染文本的字形特征，同时使用 LLM（大语言模型，作为文本编码器）和 ByT5 模型进行编码。\n\nLLM 擅长捕捉文本的整体语义，尤其对中文复杂语境（如诗词、传统民俗描述）、文化内涵有深度理解。它能从海量数据中学习中文文化特征，确保生成图像准确表达文本语义，例如在生成包含中国传统元素的图像时，精准传递文化细节。作为双语编码器，LLM 支持中英双语语义对齐，使模型在处理双语提示时，保持跨语言生成的一致性。\n\nGlyph-Aligned ByT5专注于字符级特征处理，解决文本渲染中的布局混乱、字符重复等问题。例如，在长文本或复杂排版（如竖排中文、书法字体）中，通过字符级嵌入对齐，实现高精度的文本布局生成，确保文字排列符合视觉逻辑。对多语言字符的细节处理更精细，提升模型在不同语言文本渲染任务中的普适性，尤其在非英文文本（如中文、日文）的排版中表现更优。\n\nDiffusion的架构是dit，运用了针对分辨率的Scaling ROPE，使得同样图片在不同尺寸下能有相似的positional encoding。\n### 后训练\n\n后训练分为四个阶段：\n1) Continue Training (CT) and Supervised fine-tuning (SFT) stages remarkably enhance the aesthetic appeal of the model; \n2) Human Feedback Alignment (RLHF) stage significantly improves the model’s overall performance across all aspects via self-developed reward models and feedback learning algorithms; \n3) Prompt Engineering (PE) further improves the performance on aesthetics and diversity by leveraging a fine-tuned LLM; \n4) Finally, a refiner model is developed to scale up the resolution of an output image generated from our base model, and at the same time fix some minor structural errors.\n\nCT用了两种数据，机器从训练数据里筛选的高质量数据，以及人工选择的艺术/摄影/设计作品，按照一定的比例混合。训练的时候用了Value Mixing Control (VMix) Adapter，能更好的区分内容和美学的prompting，使得整体模型生成的图片更好看。SFT 整合了一些有标签的正样本，和一些模型生成的负样本来继续训练。\n\nRLHF用了一个支持双语的clip作为reward mode，同时也用了 a image-text alignment RM, an aesthetic RM, and a text-rendering RM。\n\nPE也分为两个阶段。第一个阶段是supervised llm fine-tuning，建立了一个pe模型 u -> r，u是原始的prompt，r是模型改良的prompt。训练方法一是不断改进r，使得 u能通过r生成一个好的图片。二是找高质量文本对，不断地减少r的描述来还原u。第二个阶段是rlhf，通过第一阶段的pe生成很多prompt，然后人工选取positive negative pairs来做rl。\n\nRefiner仍然是两个阶段。第一阶段是1024分辨率scaling，第二阶段找了一些高质量texture数据做downgrade，然后用这些数据训练了一个texture模型用来guide refiner 模型。\n\n### Instruction-Based Editing\n\n运用了自研的SeedEdit，区别于其他solution，SeedEdit用diffusion作为encoder。为了改善人脸一致性的问题，用了内部的 ID/IP 模型，以及收集了很多ID/IP在不同条件下的图片。同时，模型结构引入了perception loss（face loss）来保持人脸一致性。\n\n### 模型加速\n\nTrajectory Segmented Consistency Distillation (TSCD) methodology，把 [0,T] 的时间段分为k segment，在训练的过程中逐渐减少。Quantization上也做了微调，支持不同模型部分的量化。\n\n\n","tags":["技术","豆包","论文"]},{"title":"2025-03-15 本周播客记录","url":"/2025/03/15/2025-03-15 本周播客记录/","content":"### 硅谷101 E183：比特币巨鲸策略 microstrategy\n\n这篇播客讲述了美股微策略公司的运行逻辑，这个公司会发债/融资大量购买比特币，提供相对于btc etf更大的流动性。因为自带高杠杆加上high volatility，hf或者其他玩家很喜欢买他。并且他是美股，所以很多没办法买etf的资金（国外的养老基金，州基金）也可以买。而被制裁的国家现在也在推荐多弄一些btc储备。这个公司ceo非常会做营销，并且宣传的卖点就是高波动，最近在跟美国政府的交流中建议美国多搞点不止比特币的储备。\n\n更深有感触的一点是，嘉宾最后提到了链上经济的意义，在这个国与国冲突加剧的时间，谁能主导链上经济那么谁将会主导全球的经济。比如cn控制资金外流，但是假如有了一个很大的链上经济那么流动性全都跑过去了。这个嘉宾也之前也讲了tether，usdt稳定币的公司，你越买稳定币相当于直接买美债了（tether已经是美国第18大债主，超越了很多国家）。所以，为了防止美元霸权，一些国家也在推行自己的链上交易货币。我觉得自己可能也需要搞个冷钱包屯点btc，大概 5% - 10%总资产比较合适。btc可能是偏离了传统价值投资，但是他作为新链上经济的鼻祖有着不可替代的价值。\n\n所以目前看，虽然科技上美国不一定能继续霸权，国内川皇马一龙乱搞通胀已经越来越高了，但是美元的霸权目前来看全世界毫无替代。\n### 潜空间：季雨，谁困住了ai产业大型机化的计算机形态与变革的可能\n\n官方笔记：[https://miracleplus.feishu.cn/docx/SngpdNt4XoNXHvxzFkFcJNd5nGh](https://miracleplus.feishu.cn/docx/SngpdNt4XoNXHvxzFkFcJNd5nGh)\n\n作者回顾了人工智能发展的历史，并说明大模型的scaling阶段是处在l2 - l3的阶段。但是它上限就在这里，尽管o1带来了rl post training的范式，目前大模型的能力上线就是语言这个复杂系统的上线。（嘉宾顺口提及了复杂系统会带来全新的能力，比如每个人的组成大家都知道，但是这个社会由于特别多的人的相互作用，变成了一个复杂的系统，产生了远超于每个人本身组成的能力）然后嘉宾回顾了一下pc时代和互联网时代，发现是因为大模型时代缺乏一个\"更低的成本，完整的功能，并支持开放和兼容\"的生态，也就是说缺少一个llm时代的商业模型。\n\n![](/img/2025/03/image-20250315211858.png) \n\n在大型机 - 个人机的时代，intel发明的微型芯片使得每个人都能接触到计算机和智能时代，并且人们著需要一次买断就能后续一直使用。在互联网时代，最伟大的发明是\"羊毛出在羊身上\"，也是人类历史上最伟大的商业模式：广告。用户通过出售注意力获得服务，催生了推荐系统的研究。但是目前，nvda这种高溢价卖显卡和其他公司卖token的商业模式明显不如前两个，所以短期也不能真正的改变世界。作者认为，现在买家觉得成本太高，开发者的roi又很低，所以这种超算的模式需要转换到个人设备上，才能开启新的时代。至于他自己的公司我没怎么听，但是这个历史讲的别有有意思。一方面我很认同他的观点，另一方面他也cover到了我很多没想到的地方（pc时代）。\n### 高能量 160 - 161：解读政府工作报告，ai人才争夺战\n\n第一个节目是解读政府的报告，强调了政府对科技的重视，具体没什么印象了。\n\n第二个节目是一个ai 猎头公司，讲述国内公司对于ai人才的追求。13年的时候，美国的人才并不愿意回去，因为待遇差（钱少事多）。但是从2024以来，越来越多的人才开始回流。成体的趋势有一点马太效应，巨头愿意花大钱抢顶级人才，但是差一点的人才并不好找工作。嘉宾预言，次一级别的人才可能需要进入传统公司，比如国内某租房软件吸引了一大波人才，做了ai转型。然后强调了宇宙厂字节不惜一切代价，重金挖人，张一鸣亲自1对1接触很多ai人才。\n\n我的感想是，本人也是属于次级人才，所以很能体会嘉宾说的只有头部人才好找工作的问题。那么除了让自己不断学习成为头部人才，短期内也要考虑非科技行业。\n### 晚点聊85： 国家从无到有\n\n从零开始建设国家比起点小说要困难的多，即使开了外挂也得好多年。\n### 人民公园说ai：豆包只是产品的中间态\n\n讲了字节系的豆包/扣子开发者大会。感受是字节系确实nb，愿意烧钱也烧的起钱，不论是产品，科研，人才全部都拿下了，目前感觉是国内唯一t0。阿里也不错，其他几家拉跨了一点。\n### 硬地骇客88： 开发翻译产品\n\n嘉宾是字节系的前pm，自己通过用chatgpt开发了一个漫画翻译app，实现了盈利。\n### 六岔路口：宠物需要的情绪价值很难替代\n\n阿里高管出来创业，做狗粮品牌。强调了创业更难，但是自己会有心理上的轻松，团队也相对松散。嘉宾强调了现在人和宠物的链接，并且人的belief会影响他对于宠物产品的消费：比如说，假如一个人很重视饮食的健康，那么他在选购狗粮时也会买强调这个饮食健康的品牌。\n\n### 科技早知道：从deepseek到manus\n\n女嘉宾号称是前open ai研究员，但是听上去感觉对ai了解极其有限。比如，她对于开源项目的商业化缺乏了解，不清楚开源到底靠什么赚钱的。并且也有一些明显错误的技术认识，比如\"开源模型的api一定比自己部署贵\"。尽管徐老师和男嘉宾尽力了，但是由于女嘉宾占的篇幅比较多带不动。听了差不多等于没听。\n\n\n\n","tags":["podcast","技术"]},{"title":"为什么要写博客","url":"/2025/03/14/为什么要写博客/","content":"最早有这个想法是一段时间之前的失眠，当时读了一本书讲到写日记/记录可以帮助睡眠。原理大概如下，如果每天睡觉前把今天的想法，和对未来的预期都写写下来，那大脑就会更放松。这样，也就不会在床上翻来覆去脑子里有很多想法。（“给思考减负：把日常的思考和琐事都记录下来。脑子需要操心的变少了，灵感变多了”， Sheng Xu 2025）我觉得确实，人的脑容量极其有限，但是和gpu集群相比虽然我们能耗很低，但是我们的学习能力应该是这一台基于backprop的模型不能比较的。那么我们确实没有必要和大模型去竞争记忆力，而是应该关注思考模型和学习模型。不重要的东西那就应该记下来，没必要占用大脑的缓存。\n\n而在llm来了以后，我意识到了我对于llm有一点过于依赖了，能用llm解决的绝对不自己想。当然，一方面效率确实提高了，我在很短的时间学习到了很多知识。不过这种知识真的有用吗？一个人再怎么学也没有大模型学的快学的多吧？可能更多还是需要学习思维模型。另外一方面，由于过于依赖，我一时到了我的思考能力和语言能力都有不同程度的下滑。比如说，以前我的文章写得也不好，但是现在倒是变成提笔之后脑子完全崩不住来几个字了。鉴于这种情况，并且最近偶然翻到四火老师早期的文章，我意识到了可能在一些时候我需要脱离ai来保证我个人的状态，而其中一个方式就是不借助ai写博客。中文和英文我感觉没有特别大的所谓哈哈，中英夹杂更好一点。\n\n除了保持自己的思考和语言能力，我也希望建立一个个人的知识库，来记录我不同时期的想法，并且可以在未来进行复盘。这个可以追溯到我早期的投资笔记，我忘了在哪里学习到把自己每次做决定的想法，交易决定的内容，和后面的回顾记录下来看。这样，能够更好的复盘反思，因为如果不记录的话人的回忆是不靠谱的。另外呢，之前在别人博客也看到可以直接用curosr + markdown当作一个rag系统。\n\n","tags":["思考","杂谈"]},{"title":"关于运动的思考","url":"/2025/03/14/关于运动的思考/","content":"\n## 关于运动的思考\n\n这篇文章记录了我对运动和康复领域的一些思考。\n\n### 热身和康复\n\n在哥大读研的时候，我经常去哥大健身房运动，毕竟纽约免费的离我近的健身房实在是不多。由于健身房规模有限，器械少学生多，很多时候都不能按照自己的计划来。我犯的最大的错就是，为了追求单词健身时间的最小化，经常省略热身和拉伸环节。当然更多的是思想上的欠缺，觉得说好像热身和拉伸无所谓，所以我付出了膝盖和肩膀受伤的惨痛代价，并且直到今日还时不时有后遗症。\n\n根据我个人的理解，热身主要是两方面，生理上的准备和神经/心理上的准备。生理上的准备就是，当我们身体热起来以后，肌肉会膨胀，关节会分泌润滑液，所以phyiscally 运动表现就是更好。心理上的准备是，比如我们看到一个特别重的物体，那我们在想要把他举起来之前，我们的大脑皮层会会告诉神经：这玩意老重了，你得小心点多用里。那么，我们就会蹲下来，小心的很用力举起来。反之，看到一个很轻的东西比如一个泡沫轴，那我们就随便直接弯腰去捡了。\n\n所以现在我在健身和跑步前一定会热身，练完也需要拉伸和放松。这个确实能帮助我避免伤病，起码我现在膝盖和肩膀的老问题不怎么反复了。但是呢，也造成了我现在肌肉增长速度的放缓：我现在可能会做更多功能性训练，而不是肌肥大训练。并且训练的时候，宁愿少长点肌肉也要保证运动的安全，可能是我个性如此。就像巴菲特还是芒格说的，我如果我知道要死在什么地方那我就不会去，所以我并不喜欢极限运动，甚至包括滑雪和过山车。\n\n\n运动前热身的优点和必要性可以从以下几个方面进行简短描述：\n\n1. **提高身体温度和血液循环**：热身可以逐渐升高体温，促进血液循环，使血液流向肌肉，增加氧气供应，从而为高强度运动做好准备。\n\n2. **减少受伤风险**：热身通过增加肌肉弹性、关节活动范围和神经传导速度，降低肌肉拉伤和关节损伤的风险。\n\n3. **提升运动表现**：热身可以增强肌肉力量和速度，改善肌肉协调能力，减少肌肉黏滞性，从而提高运动表现。\n\n4. **心理准备**：热身有助于集中注意力，调整心理状态，为接下来的运动做好心理准备。\n\n\n\n### 运动的好处\n\n根据metaso，运动的好处如下：\n\n运动的好处可以从多个方面进行总结，包括身体健康、心理健康、社交能力和生活质量的提升。以下是运动的主要好处：\n\n1. **身体健康**：\n   - **增强心肺功能**：运动可以提高心肺功能，增强血液循环，降低心血管疾病的风险。\n   - **控制体重**：通过燃烧脂肪和增加肌肉量，运动有助于减肥和维持健康的体重。\n   - **改善代谢**：运动促进新陈代谢，提高身体对糖和脂肪的利用效率，预防糖尿病和肥胖。\n   - **增强免疫力**：规律运动可以提高免疫系统的功能，减少疾病的发生。\n   - **预防慢性疾病**：运动有助于降低高血压、高血糖、心脏病等慢性疾病的风险。\n   - **改善骨骼健康**：运动可以增强骨密度，预防骨质疏松症。\n\n2. **心理健康**：\n   - **缓解压力和焦虑**：运动可以释放内啡肽等“快乐激素”，帮助减轻压力和焦虑。\n   - **改善情绪**：运动能够提升心情，增强自信心，减少抑郁情绪。\n   - **提高专注力**：运动有助于集中注意力，提升大脑的工作效率。\n\n3. **社交能力**：\n   - **扩大社交圈**：通过团队运动或健身活动，可以结交新朋友，培养合作精神和团队意识。\n   - **增进亲子关系**：共同参与运动可以增进家庭成员之间的交流和理解。\n\n4. **生活质量**：\n   - **提升活力**：运动可以增强体力和耐力，使人更加精力充沛。\n   - **改善睡眠质量**：规律运动有助于调整生物钟，改善睡眠质量。\n   - **延缓衰老**：运动可以延缓身体机能的衰退，保持身体的灵活性和活动能力。\n\n我在atl待的这段时间经常感到抑郁，所以我会每天都运动。当然身体健康我可能没感受到，还是时不时生病或者运动受伤，但是心理健康有明显的改善。\n\n\n### 不同的快乐激素\n\n### 内啡肽、催产素与多巴胺的功效及产生行为总结\n\n内啡肽，多巴胺和催产素都是快乐激素。我的理解是，内啡肽需要的是长期并略有痛苦的行为，比如运动。多巴胺是最短期的激素，比如打游戏，运动，性都可以提供。但是在现代社会下，多巴胺也非常容易被滥用的，比如电子游戏和黄色很容易让你快乐，但是快乐完只会感受到空虚。相比之下，运动完的快乐会更持久，也更令人开心。虽然很多时候知道，但是没办法控制自己，因为现在状态确实不好，压力很大。\n\n#### **1. 内啡肽（Endorphins）**  \n**功效**：  \n- **缓解疼痛**：作为天然止痛药，通过抑制疼痛信号传递减轻痛感。  \n- **产生欣快感**：与吗啡受体结合，带来类似吗啡的愉悦感和放松效果。  \n- **增强运动耐力**：在运动中帮助隐藏身体痛苦，促进持续锻炼。  \n- **提升免疫力和睡眠**：改善免疫功能，调节睡眠质量。  \n\n**触发行为**：  \n- **高强度运动**：如跑步、游泳、举铁（持续30分钟以上）。  \n- **饮食**：食用黑巧克力、辛辣食物（如辣椒）。  \n- **情绪行为**：大笑（如看喜剧）、按摩。  \n\n---\n\n#### **2. 催产素（Oxytocin）**  \n**功效**：  \n- **促进母婴关系**：刺激乳汁分泌、激发母爱，帮助分娩时子宫收缩。  \n- **增强社交信任**：被称为“爱的激素”或“信任激素”，抑制恐惧和防御心理，增进人际信任。  \n- **缓解压力**：降低压力激素（如肾上腺酮）水平，稳定血压和心率。  \n- **促进亲密关系**：在拥抱、性行为等亲密互动中释放，巩固情感纽带。  \n\n**触发行为**：  \n- **身体接触**：拥抱、亲吻、性行为。  \n- **社交互动**：与亲友对话、陪伴、参与集体活动。  \n- **利他行为**：帮助他人、表达善意（如赞美、捐赠）。  \n- **母婴行为**：哺乳、母婴皮肤接触。  \n- **宠物互动**：与宠物玩耍或凝视。  \n\n---\n\n#### **3. 多巴胺（Dopamine）**  \n**功效**：  \n- **激励与奖赏**：驱动目标导向行为，带来短暂的兴奋感和满足感（如完成目标后的愉悦）。  \n- **调节情绪**：缺乏时可能导致抑郁、冲动或动力不足。  \n- **影响成瘾机制**：与愉悦和“上瘾”行为（如游戏、爱情初期）密切相关。  \n- **促进运动与学习**：通过奖赏机制鼓励重复有益行为（如运动、学习）。  \n\n**触发行为**：  \n- **达成目标**：完成小任务、获得成就（如工作、学习）。  \n- **饮食与娱乐**：吃巧克力、听音乐、观看喜剧。  \n- **运动与性行为**：锻炼、性爱。  \n- **社交互动**：与朋友聚会、建立新关系。  \n\n\n\n\n","tags":["思考","杂谈","生活","运动"]}]